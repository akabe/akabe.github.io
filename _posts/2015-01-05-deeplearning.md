---
layout: post
title: "ニューラルネットの歴史と深層学習のサーベイ"
date: 2015-01-05
category: 深層学習
---

しばらく前の研究室ゼミで発表した，ニューラルネットの歴史と深層学習に関するスライドをアップします．
[Download PDF]({{ site.baseurl }}/slides/HistoryOfNeuralNetworksAndDeepLearning.pdf)

<center>
<object type="application/pdf" width="640" height="360"
    data="{{ site.baseurl }}/slides/HistoryOfNeuralNetworksAndDeepLearning.pdf">
[Download PDF]({{ site.baseurl }}/slides/HistoryOfNeuralNetworksAndDeepLearning.pdf)
</object>
</center>

パーセプトロンなどのニューラルネットの初期の研究から，
過去2回あった「ニューラルネット冬の時代」，深層学習 (deep learning) に関する最近の研究まで，
広く浅く取り上げています．確率論とか数学の話には，あまり立ち入らないように説明しているので，
手っ取り早く概要を把握して，理解した気になりたい人用の内容です．
（と言いつつ，deep belief nets とか有名な研究をサーベイし忘れています．）

ニューラルネットがよくわかんない状態から1ヶ月ぐらいで勉強した内容なので，
間違っているところも多いかもしれません．英語で書いていますが，そっちもかなりいい加減なので，
意味不明なところや間違ったところを見つけた人は，twitter か
[GitHub の Issues](https://github.com/akabe/akabe.github.io/issues)
で教えてくれると有難いです（twitter の場合はエアリプだと見逃すかもしれないので，リプライにして下さい）．

【謝辞】特徴ベクトルからパーセプトロンまでの説明は TH 大学 I 教授のスライドを参考，というかほぼそのままです．
私が見た中で，最もわかりやすい説明なので，勝手に真似しました．すみません．
